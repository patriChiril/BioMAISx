{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data to train with InstructABSA\n",
    "\n",
    "To use this data for to train InstructABSA [[GitHub](https://github.com/kevinscaria/InstructABSA), [paper](https://arxiv.org/abs/2302.08624)], run the following cells. This will output the data in the correct format to train the model.\n",
    "\n",
    "## Training with InstructABSA\n",
    "\n",
    "Clone the InstructABSA Github repository, place the formatted BioMAISx data in the Dataset folder, and train with the joint task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "REPO_ROOT = Path().resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_InstructABSA(df, instances=None):\n",
    "    \"\"\"Df should have 'proposed_entity_type',... 'set'\"\"\"\n",
    "\n",
    "    def format_dataframe_InstructABSA(df):\n",
    "        # Create a DataFrame to hold the transformed data\n",
    "        transformed_data = []\n",
    "\n",
    "        for _, group in df.groupby(\"quote_id\"):\n",
    "            sentence_id = group[\"quote_id\"].iloc[0]\n",
    "            raw_text = group[\"quote_string\"].iloc[0]\n",
    "            aspect_terms = []\n",
    "\n",
    "            for index, row in group.iterrows():\n",
    "                aspect_term = {\"term\": row[\"proposed_entity\"], \"polarity\": row[\"sentiment\"]}\n",
    "                aspect_terms.append(aspect_term)\n",
    "\n",
    "            transformed_data.append([sentence_id, raw_text, aspect_terms])\n",
    "\n",
    "        # Create the DataFrame with the desired format\n",
    "        transformed_df = pd.DataFrame(\n",
    "            transformed_data, columns=[\"sentenceId\", \"raw_text\", \"aspectTerms\"]\n",
    "        )\n",
    "\n",
    "        # Add the aspectCategories column\n",
    "        transformed_df[\"aspectCategories\"] = (\n",
    "            \"[{'category': 'noaspectcategory', 'polarity': 'none'}]\"\n",
    "        )\n",
    "\n",
    "        return transformed_df\n",
    "\n",
    "    output_directory = REPO_ROOT / \"datasets\" / \"InstructABSA\"\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "    paper_names = {\n",
    "        \"train\": \"mbio_Train\",\n",
    "        \"test\": \"mbio_Test\",\n",
    "        \"validation\": \"mbio_Validation\",\n",
    "    }\n",
    "    for set in [\"train\", \"test\", \"validation\"]:\n",
    "        temp_df = df[df[\"set\"] == set]\n",
    "        result = format_dataframe_InstructABSA(temp_df)\n",
    "        result = result.set_index(\"sentenceId\")\n",
    "        if instances is not None and set == \"train\":\n",
    "            # Shuffle the DataFrame\n",
    "            shuffled_df = result.sample(\n",
    "                frac=1, random_state=42\n",
    "            )  # Use a random_state for reproducibility\n",
    "\n",
    "            # Create N disjoint samples of K rows\n",
    "            samples = []\n",
    "            for i in range(10):\n",
    "                sample = shuffled_df.iloc[i * instances : (i + 1) * instances]\n",
    "                samples.append(sample)\n",
    "            for i, sample in enumerate(samples):\n",
    "                sample.to_csv(output_directory / f\"{paper_names[set]}-{i}.csv\")\n",
    "        else:\n",
    "            result.to_csv(output_directory / f\"{paper_names[set]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_values_above_threshold(df: pd.DataFrame, n: int) -> list[(str, str)]:\n",
    "    \"\"\"Given a df, return all row, column pairs by name with value > n\"\"\"\n",
    "    name_pairs = []\n",
    "    for column in df.columns:\n",
    "        for index, value in df[df[column] > n].iterrows():\n",
    "            name_pairs.append((index, column))\n",
    "    return name_pairs\n",
    "\n",
    "\n",
    "def filter_dataset(df: pd.DataFrame, min_instances=50) -> pd.DataFrame:\n",
    "    \"\"\"Eliminate samples with under min_instances\"\"\"\n",
    "    pivot_table = df.pivot_table(\n",
    "        index=\"aspect\", columns=\"entity_type\", aggfunc=\"size\", fill_value=0\n",
    "    )\n",
    "    entity_type_aspect_pairs = find_values_above_threshold(pivot_table, min_instances)\n",
    "    print(entity_type_aspect_pairs)\n",
    "    filtered_dataset = df[\n",
    "        df.apply(\n",
    "            lambda row: (row[\"aspect\"], row[\"entity_type\"]) in entity_type_aspect_pairs,\n",
    "            axis=1,\n",
    "        )\n",
    "    ]\n",
    "    return filtered_dataset\n",
    "\n",
    "def assign_sets_to_dataframe(df, train, test, validation):\n",
    "    def assign_by_row(row):\n",
    "        if row[\"quote_id\"] in train:\n",
    "            return \"train\"\n",
    "        elif row[\"quote_id\"] in test:\n",
    "            return \"test\"\n",
    "        elif row[\"quote_id\"] in validation:\n",
    "            return \"validation\"\n",
    "        else:\n",
    "            print(row)\n",
    "            return \"unknown\"\n",
    "\n",
    "    df[\"set\"] = df.apply(assign_by_row, axis=1)\n",
    "    return df\n",
    "\n",
    "def assign_sets(filtered_dataset: pd.DataFrame) -> pd.DataFrame:    \n",
    "    temp_df = filtered_dataset.groupby(\"quote_id\")[[\"entity_type\", \"aspect\"]].first()\n",
    "    X = temp_df.index\n",
    "    y = temp_df[[\"entity_type\", \"aspect\"]]\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    X_test, X_validation, y_test, y_validation = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.33, stratify=y_temp, random_state=42\n",
    "    )\n",
    "\n",
    "    formatted_data = assign_sets_to_dataframe(filtered_dataset, X_train, X_test, X_validation)\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Consumer Perception', 'Crops'), ('Economic Impact', 'Crops'), ('Food Security', 'Crops'), ('Productivity', 'Crops'), ('Resistance', 'Crops'), ('Economic Impact', 'Economic Factors'), ('Productivity', 'Environmental Conditions'), ('Consumer Perception/Nutrition', 'GM Crop'), ('Economic Impact', 'GM Crop'), ('Food Security', 'GM Crop'), ('Miscellaneous', 'GM Crop'), ('Productivity', 'GM Crop'), ('Resistance', 'GM Crop'), ('Productivity', 'Geographical Location'), ('Economic Impact', 'Legal Aspects and Politics'), ('Productivity', 'Legal Aspects and Politics'), ('Economic Impact', 'Organizations'), ('Environment and Ethical Concerns', 'Organizations'), ('Productivity', 'Organizations'), ('Economic Impact', 'Technology'), ('Productivity', 'Technology'), ('Productivity', 'Weather/Climate')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77014/401261695.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"set\"] = df.apply(assign_by_row, axis=1)\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ANNOTATIONS = REPO_ROOT / \"BioMAISx-CIKM.csv\"\n",
    "\n",
    "annotations = pd.read_csv(PATH_TO_ANNOTATIONS)\n",
    "filtered_annoatations = filter_dataset(annotations, min_instances=50)\n",
    "annotations_split = assign_sets(filtered_annoatations)\n",
    "\n",
    "format_data_for_InstructABSA(annotations_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
